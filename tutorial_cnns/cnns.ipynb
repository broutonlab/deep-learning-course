{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Install service functions for the notebook\n",
        "\n",
        "!pip install \"git+https://github.com/broutonlab/deep-learning-course.git\"\n",
        "import dl_course"
      ],
      "metadata": {
        "id": "nRTgzZ8DqvB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bg_xWFCq_6S-"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "\n",
        "!pip install pytorch-lightning\n",
        "!pip install ipyplot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download dataset\n",
        "import ipyplot\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from dl_course.cnns.utils import *\n",
        "\n",
        "DATASET_PATH = \"satellite_dataset\"\n",
        "\n",
        "download_dataset(DATASET_PATH, \"1LOO2U1xSnGByYHzlt7siCBn1G3Jaq_Gs\")"
      ],
      "metadata": {
        "id": "dE42ujQbSdNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# [!] If cuda is not available,\n",
        "# start using 'TPU' or 'GPU' in notebook settings\n",
        "print(f'Cuda available: {torch.cuda.is_available()}')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ],
      "metadata": {
        "id": "iGekA6zPfa_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Meet the RSI-CB256 dataset\n",
        "\n",
        "For this notebook we'll be using a portion of satellite image classification dataset (https://www.kaggle.com/datasets/sohelranaccselab/satellite-data)\n",
        "\n",
        "Your task will be to implement a classifier that can guess some types of sceneries using satellite imagery data."
      ],
      "metadata": {
        "id": "RTKqZxEyfTUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preview_dataset(DATASET_PATH, num_images=5)"
      ],
      "metadata": {
        "id": "uWKJqYfPfT_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset initialization\n",
        "\n",
        "Our dataset contains three files, already split for you into:\n",
        "- train.csv (70% of the whole data)\n",
        "- val.csv (15%)\n",
        "- test.csv (15%)"
      ],
      "metadata": {
        "id": "-6nORFUsyJw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "import torchvision.transforms as T\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "\n",
        "# we'll have separate instances of this class for train, val, test\n",
        "class SatelliteDataset(Dataset):\n",
        "  def __init__(self, data: pd.DataFrame, labels: list):\n",
        "    super().__init__()\n",
        "    self.data = data\n",
        "    self.resize_transform = T.Resize(size = (256, 256))\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.data.iloc[idx]\n",
        "    y = row[1]\n",
        "\n",
        "    # converting label to onehot encoding\n",
        "    y_onehot = [1 if label == row[1] else 0\n",
        "                for label in self.labels]\n",
        "    y_onehot = torch.tensor(y_onehot).float()\n",
        "\n",
        "    X = read_image(os.path.join(DATASET_PATH, row[0]))\n",
        "    # we are resizing all images, although you can try implementing \n",
        "    # an architecture that is able to handle images of different sizes\n",
        "    if X.size() != (256, 256):\n",
        "      X = self.resize_transform(X)\n",
        "\n",
        "    # convert uint8 ([0, 255]) to float ([0, 1])\n",
        "    X = X.float() / 255\n",
        "\n",
        "    return {\n",
        "        \"X\": X,\n",
        "        \"y\": y_onehot\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "# this is just an initializer of train, val and test datasets\n",
        "class SatelliteDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, data_folder: str, labels: list,\n",
        "               batch_size: int, num_workers: int = None):\n",
        "    super().__init__()\n",
        "    self.data_folder = data_folder\n",
        "    self.batch_size = batch_size\n",
        "    self.num_workers = os.cpu_count() if num_workers is None else num_workers\n",
        "\n",
        "  def _load_dataframe(self, filename: str):\n",
        "    csvfile = os.path.join(self.data_folder, filename)\n",
        "    return pd.read_csv(csvfile)\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(\n",
        "        dataset=SatelliteDataset(self._load_dataframe(\"train.csv\"), labels),\n",
        "        batch_size=self.batch_size,\n",
        "        num_workers=self.num_workers,\n",
        "        shuffle=True)\n",
        "    \n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(\n",
        "        dataset=SatelliteDataset(self._load_dataframe(\"val.csv\"), labels),\n",
        "        batch_size=self.batch_size,\n",
        "        num_workers=self.num_workers)\n",
        "    \n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(\n",
        "        dataset=SatelliteDataset(self._load_dataframe(\"test.csv\"), labels),\n",
        "        batch_size=self.batch_size,\n",
        "        num_workers=self.num_workers)"
      ],
      "metadata": {
        "id": "gl-4b-DQxUrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement your model\n",
        "\n",
        "Let's jump right into the code and implement a simple architecture."
      ],
      "metadata": {
        "id": "43y1Ns4bJl6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "class SatelliteCNN(pl.LightningModule):\n",
        "\tdef __init__(self, num_classes=None, learning_rate=None):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.learning_rate = learning_rate\n",
        "\t\tself.num_classes = num_classes\n",
        "\t\tself.cnn = nn.Sequential(\n",
        "\t\t\t\t# ===============\n",
        "\t\t\t\t# [!] TODO: \n",
        "\t\t\t\t# \tThe first layer of our network \n",
        "\t\t\t\t# \twill be a convolutional layer.\n",
        "\t\t\t\t#\t\tIt takes original image (3 channels, 256x256) as input\n",
        "\t\t\t\t#\t\tand should output two 32x32 feature maps\n",
        "\t\t\t\t#\t\t(you'll see if it's an appropriate choice later).\n",
        "\t\t\t\t#\t\t\n",
        "\t\t\t\t# \tYou need to figure the parameters of the layer\n",
        "\t\t\t\t# \tso that output shapes match. (we chose kernel_size=16 for you)\n",
        "\t\t\t\t# \tYou may this calculator:\n",
        "\t\t\t\t# \thttps://madebyollin.github.io/convnet-calculator/\n",
        "\t\t\t\t#   Or the docs:\n",
        "\t\t\t\t#   https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "\t\t\t\tnn.Conv2d(in_channels=...,\n",
        "\t\t\t\t\t\t\t\t\tout_channels=...,\n",
        "\t\t\t\t\t\t\t\t\tkernel_size=16,\n",
        "\t\t\t\t\t\t\t\t\tstride=...,\n",
        "\t\t\t\t\t\t\t\t\tpadding=4),\n",
        "\t\t\t\t# ===============\n",
        "\t\t\t\tnn.ReLU(),\n",
        "\t\t\t\tnn.BatchNorm2d(2),\n",
        "\t\t\t\tnn.Flatten(start_dim=1),\n",
        "\t\t\t\tnn.Linear(2*32*32, 8*8),\n",
        "\t\t\t\tnn.ReLU(),\n",
        "\t\t\t\t# ===============\n",
        "\t\t\t\t# [!] TODO: \n",
        "\t\t\t\t# \tImplement final affine layer\n",
        "\t\t\t\t...\n",
        "\t\t\t\t# ===============\n",
        "\t\t\t\tnn.Softmax(-1)\n",
        "      )\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\t# ===============\n",
        "\t\t# [!] TODO: implement forward pass for our model\n",
        "\t\treturn ...\n",
        "\t\t# ===============\n",
        "\n",
        "\tdef configure_optimizers(self):\n",
        "\t\t# ===============\n",
        "\t\t# [!] TODO: configure optimizer.\n",
        "\t\t# Let's use Adam. Don't forget to use self.learning_rate\n",
        "\t\t# https://pytorch.org/docs/stable/optim.html\n",
        "\t\treturn ...\n",
        "\t\t# ===============\n",
        "\n",
        "\tdef loss_fn(self, y_hat, target):\n",
        "\t\treturn nn.CrossEntropyLoss()(y_hat, target)\n",
        "\t\n",
        "\tdef _eval_step(self, x, y):\n",
        "\t\timg = x.view(-1, 3, 256, 256)\n",
        "\t\ty_hat = self.forward(img)\n",
        "\t\tloss = self.loss_fn(y_hat, y)\n",
        "\t\treturn y_hat, loss\n",
        "\n",
        "\tdef training_step(self, batch, batch_idx):\n",
        "\t\tx, y = batch[\"X\"], batch[\"y\"]\n",
        "\t\ty_hat, loss = self._eval_step(x, y)\n",
        "\t\tself.log('train_loss', loss)\n",
        "\t\treturn loss\n",
        "\n",
        "\tdef validation_step(self, batch, batch_idx):\n",
        "\t\tx, y = batch[\"X\"], batch[\"y\"]\n",
        "\t\ty_hat, loss = self._eval_step(x, y)\n",
        "\t\tself.log('val_loss', loss)\n",
        "\t\n",
        "\tdef test_step(self, batch, batch_idx):\n",
        "\t\tx, y = batch[\"X\"], batch[\"y\"]\n",
        "\t\ty_hat, loss = self._eval_step(x, y)\n",
        "\t\n",
        "\t\t_, preds = torch.max(y_hat, 1)\n",
        "\t\t_, y_labels = torch.max(y, 1)\n",
        "\t\tcorrect = torch.sum(preds == y_labels)\n",
        "\t\t\n",
        "\t\treturn {'test_loss': loss, 'correct': correct, 'num_entries': x.shape[0]}\n",
        "\n",
        "\tdef test_epoch_end(self, outputs):\n",
        "\t\tavg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
        "\n",
        "\t\tavg_acc = torch.stack([x['correct'].float() for x in outputs]).sum() \\\n",
        "\t\t\t\t\t\t/ sum(output['num_entries'] for output in outputs)\n",
        "\n",
        "\t\tlogs = {'test_loss': avg_loss, 'test_acc': avg_acc}\n",
        "\t\tself.log_dict(logs)\n",
        "\n",
        "\n",
        "# if you get \"out of memory\" errors,\n",
        "# reduce the batch size\n",
        "batch_size = 32\n",
        "\n",
        "labels = [\"bridge\", \"coastline\", \"dam\", \"highway\", \"parkinglot\", \"river\"]\n",
        "\n",
        "# data\n",
        "datamodule = SatelliteDataModule(\"satellite_dataset/\", labels, batch_size=batch_size)\n",
        "\n",
        "# model\n",
        "model = SatelliteCNN(num_classes=len(labels), learning_rate=1e-3)"
      ],
      "metadata": {
        "id": "rmr_TZjiRQdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sanity check\n",
        "\n",
        "It is reasonable to start our training with small number of batches to test if every line of our code works"
      ],
      "metadata": {
        "id": "6xih3pPt7rZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if everything runs OK:\n",
        "trainer = pl.Trainer(accelerator='gpu', devices=-1, fast_dev_run=3)\n",
        "trainer.fit(model=model, datamodule=datamodule)"
      ],
      "metadata": {
        "id": "nYuBohJ072Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model\n",
        "\n",
        "This may take a while..."
      ],
      "metadata": {
        "id": "YpTK-96G743-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logger = pl.loggers.TensorBoardLogger(\"tb_logs\", name=\"satellite_cnn\")\n",
        "trainer = pl.Trainer(accelerator='gpu', devices=-1, max_epochs=15, log_every_n_steps=20, logger=logger)\n",
        "trainer.fit(model=model, datamodule=datamodule)"
      ],
      "metadata": {
        "id": "Gz-hoZ7n8D-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test model performance"
      ],
      "metadata": {
        "id": "RAMd8HHl8IVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(model=model, datamodule=datamodule)"
      ],
      "metadata": {
        "id": "uxl6dqyhv_du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize the model"
      ],
      "metadata": {
        "id": "-ZElUzRR0u-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model(model, datamodule, labels, num_images=6)"
      ],
      "metadata": {
        "id": "P_qnuNYX0xq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorboard\n",
        "\n",
        "This is a dashboard that allows you to monitor different metrics during training and across multiple runs.\n",
        "(it won't load instantly though)\n",
        "\n",
        "'train_loss' and 'val_loss' time series are our primary subjects of interest."
      ],
      "metadata": {
        "id": "OlpVWuvV_5Ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir tb_logs/"
      ],
      "metadata": {
        "id": "D_LamoAB_8es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evalute the results\n",
        "\n",
        "If you've done everything right, you should see about 58% (or at least >45%) accuracy on test dataset.\n",
        "\n",
        "This performance is not satisfactory."
      ],
      "metadata": {
        "id": "eymzPuGDuEeU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Home task: improve your model\n",
        "\n",
        "We've been able to easily achieve >90% accuracy on test dataset, and you should too!\n",
        "\n",
        "We'll provide some tips on how to do it below."
      ],
      "metadata": {
        "id": "DvWUHGaIvi30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Increase number of epochs\n",
        "\n",
        "Number of epochs needed to train your model may vary with model parameters and augmentations.\n",
        "\n",
        "Keep an eye on validation loss. If it stops decreasing long before the final epoch or starts to increase, you probably don't need that many epochs."
      ],
      "metadata": {
        "id": "xY-uK7iBwuSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use different convolutions\n",
        "\n",
        "Our convolution outputs just 2 feature maps.  \n",
        "It is common for CNNs to have a lot more filters (64, 96, 256, etc.)  \n",
        "CNNs are often comprised of 3 or more convolutional layers, you should add more layers too.  \n",
        "Feel free to expore different CNN architectures on the web."
      ],
      "metadata": {
        "id": "rFXWlombzLcO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use max pooling\n",
        "\n",
        "Max pooling is often used to reduce dimensionality of data.  \n",
        "It is reasonable to use max pooling after convolutions and before activation functions, because\n",
        "\n",
        "$ MaxPool(ReLU(X)) = ReLU(MaxPool(X)) $  \n",
        "(think which activation functions also satisfy this equation)\n",
        "\n",
        "Max pooling, similar to convolution, won't let you define its output dimensions explicitly. You may want to use formulas provided in the docs:  \n",
        "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n"
      ],
      "metadata": {
        "id": "Bf5WoYAn1UO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use data augmentation\n",
        "\n",
        "Is a mirrored image of a river also an image of a river? Of course it is.  \n",
        "Using this logic, we can generate new datapoints using existing ones by cropping/scaling/flipping our images. \n",
        "\n",
        "One of the simpler ways to it in our code would look like this:\n",
        "```python\n",
        "import torchvision.transforms as T\n",
        "# ...\n",
        "class SatelliteDataset(Dataset):\n",
        "  def __init__(self, data: pd.DataFrame, labels: list, transform=None):\n",
        "    super().__init__()\n",
        "    self.transform = transform\n",
        "    # ...\n",
        "\n",
        "  #...\n",
        "  def __getitem__(self, idx):\n",
        "    #...\n",
        "    if self.transform:\n",
        "      X = self.transform(X)\n",
        "    #...\n",
        "\n",
        "#...\n",
        "class SatelliteDataModule(pl.LightningDataModule):\n",
        "  #...\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(\n",
        "        dataset=SatelliteDataset(\n",
        "            self._load_dataframe(\"train.csv\"), labels, \n",
        "            # you may want to wrap it in our own callable class\n",
        "            transform=T.Compose([\n",
        "              T.RandomVerticalFlip(p=0.5),\n",
        "              T.RandomHorizontalFlip(p=0.5)\n",
        "            ])),\n",
        "        batch_size=self.batch_size,\n",
        "        num_workers=self.num_workers,\n",
        "        shuffle=True)\n",
        "\n",
        "```\n",
        "\n",
        "For different types of transforms, refer here:  \n",
        "https://pytorch.org/vision/stable/transforms.html"
      ],
      "metadata": {
        "id": "ai2cSYr77USx"
      }
    }
  ]
}